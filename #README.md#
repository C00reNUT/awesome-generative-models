# awesome-generative-models
A curated list of awesome generative model frameworks, libraries, software and resources for media production

inspired by [awesome-python](https://github.com/vinta/awesome-python)
<div align="center">
	<img width="500" height="350" src="media/somercloud_1_logo.PNG" alt="Awesome">
	<br>
	<br>
	<hr>
	<p>
		<p>
			<sup>
				<a href="https://github.com/SomerCloud-Studio">My open source work is supported by the community</a>
			</sup>
</div>

- [Awesome Generative Mdels](#awesome-generative-models)

    - [Image Synthesis](#imageSynthesis)
		- [Image Style Transfer](#ImageStyleTransfer)
    - [Text Generation/NLP](#NLP)
		- [Audio and music generation/processing](#AudioAndMusicGenerationProcessing)
		- [Music-Video Synthesis](#MusicVideoSynthesis)
    - [Video-Synth](#videoSynth)
    - [Image-Generation](#imageGeneration)
    - [Forum](#forum)

## Image Synthesis
* [SPADE by NVlabs: Synthesizing photorealistic images given an input semantic layout](https://nvlabs.github.io/SPADE/).
  [code](https://github.com/nvlabs/spade/)

## Image Style Transfer
* [Artbreeder based on BigGAN models](https://artbreeder.com/)
   [opensource version](https://github.com/joel-simon/ganbreeder)
   [BigGAN models](https://tfhub.dev/deepmind/biggan-512/2)
   [About](https://artbreeder.com/about)

## Text Generation/NLP
* [OpenAI 1.5 billion params GPT-2 release](https://openai.com/blog/gpt-2-1-5b-release/)
* [AIDungeon](https://github.com/AIDungeon/AIDungeon)

## Audio and music generation/processing
### Project:
* [Talking like your favorite character: Text-To-Speech audio generation ](https://fifteen.ai/app)
related research:
* [Tacotron2](https://github.com/NVIDIA/tacotron2)
* [ForwardTacotron: Tacotron2 without attention](https://github.com/as-ideas/ForwardTacotron)
* Voice clone: [Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)
* [Spleeter: sound track seperation](https://github.com/deezer/spleeter)
  sound seperation is under domain of music information retrival.

### Music-Video Synthesis
* [Deep Music Visualizer using BigGan](https://towardsdatascience.com/the-deep-music-visualizer-using-sound-to-explore-the-latent-space-of-biggan-198cd37dac9a)
  [code](https://github.com/msieg/deep-music-visualizer)

## Video Synthesis and Generation:
* [pix2pix-tensorflow: poweed interative rendereed Virtual world](https://www.youtube.com/watch?v=ayPqjPekn7g)
  [code](https://github.com/affinelayer/pix2pix-tensorflow)
   update: pretrained model added
   [more about](https://affinelayer.com/pix2pix/)

* [CRAFT, which generates cartoons based on text descritpionsa](https://arxiv.org/abs/1804.03608)
  A very creative work involved text to video generation from allen nlp
  by [researcher](http://tanmaygupta.info/publications/)
  [Project page](https://prior.allenai.org/projects/craft)
  [Video](https://www.youtube.com/watch?v=688Vv86n0z8&feature=youtu.be)
  
## Animation
*[deep learning for character animation and control](https://github.com/sebastianstarke/AI4Animation)
*[DeepMimic: Motion imitation with deep reinforcement learning](https://github.com/xbpeng/DeepMimic)

## SEE CODE LINK:
* [Paper with code](https://paperswithcode.com/)

## Resources on related course/BLOG:
* [Chris Colah's blog](http://colah.github.io/)
* [UIUC CS598RK: HCI for ML](https://courses.grainger.illinois.edu/cs598rk/fa2019/)
* [coursera: Sequence Models](https://www.coursera.org/learn/nlp-sequence-models/)
* [Full Stack Deep Learning](https://fullstackdeeplearning.com/)
* fast.ai
* [UIUC: ECE420 Video processing lab](https://courses.grainger.illinois.edu/ece420/fa2019/lab7/lab/)
* GPU free resource:[Setting Up a Google Cloud Instance GPU for fast.ai for Free](https://medium.com/@jamsawamsa/running-a-google-cloud-gpu-for-fast-ai-for-free-5f89c707bae6)

## Full Stack Deep Learning tools in data processing pipeline:
* [cortex: Deploy machine learning models in production possibly without docker and kubernetes](https://github.com/cortexlabs/cortex)


## Resources for dev tool:
* Lumen: Video syth software
* [Dialogue tree based node editor for unity](https://github.com/Seneral/Node_Editor_Framework)
  and [example](https://github.com/Seneral/Node_Editor_Framework/tree/Examples/Dialogue-System)
  [demo](https://nodeeditor.seneral.dev/Examples.html)


## More resources on pretrained model:
 * [Pytorch hub]https://pytorch.org/hub/research-models
 * [Tensorflow hub]

## MEET mind-linked people in forum:
*[reddit-MediaSynthesis](https://www.reddit.com/r/MediaSynthesis/)

## Application:
### FILM MAKING:
* Black Mirror: Bandersnatch
  [Show case: dialogue tree](https://www.reddit.com/r/blackmirror/comments/aajk5r/full_bandersnatch_flowchart_all_branches_story/)
* [LATE-SHIFT](https://lateshift-movie.com/)